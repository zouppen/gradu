% -*- mode: LaTeX; coding: utf-8; -*-

\chapter{Tiedon keruu ja esikäsittely}

Luvussa \ref{sec:lahtokohta} kuvailtiin tutkittavien lokitiedostojen
alkuperää ja tiedostomuotoa. Tässä luvussa tutustutaan
seikkaperäisemmin siihen, miten Ixonokselta saamamme palvelinloki on
järjestetty tiedostoihin ja millä tavoin tietoa on esikäsitelty
analyysiä silmällä pitäen. Käytetyt menetelmät soveltuvat pienin
muutoksin myös muiden Web-hotellien palvelinlokien esikäsittelyyn,
mikäli arkistointikäytänteet eivät suuresti poikkea tässä esitellystä
tavasta.

Esimerkeissä käytetyt palvelinten ja palveluiden nimet ovat
kuvitteellisia, mutta rakenne vastaa tutkittua ympäristöä.

 % - Mistä data on peräisin?
 %    - Palvelun rakenteen kuvaus
 % - Millaista data on?
 %   - HTTP
 %   - Apachen logit
 % - Miten data on kerätty? (ohjelmistot ja verkkotopologia)
 %   - Yleisellä tasolla
 % - Mitä työkaluja on käytetty (Haskell ja PhasefulSplitter)
 % - Miten dataa on käsiteltu ja suodatettu?

\section{Tiedon rakenne}

Ixonoksen Web-hotelli on toteutettu siten, että yksittäiset palvelut on
sijoitettu jokaiselle palvelimelle. Ratkaisun taustalla on
kuormituksen tasaaminen. Erillinen järjestelmä huolehtii siitä, että
Internetistä tulevat kyselyt ohjataan tasaisesti eri
palvelimille. 

Taulukossa \ref{nimet} on esimerkki palveluiden ja
palvelinten nimeämisestä.

% Ei kannata ottaa esimerkkiä tästä taulukosta, tämä on vähän mutkikas.
\begin{table}[h]
\centering
\begin{tabular}{lll}
Palvelin && Palvelu \\
\cline{1-1}\cline{3-3}
dapper && buzz \\
edgy && rex \\
feisty && potato \\
&& hamm \\
&& slink \\
\end{tabular}
\caption{Palvelinten ja palveluiden nimeäminen.}
\label{nimet}
\end{table}

Lokitiedostot on sijoitettu hakemistorakenteeseen, jossa juuressa ovat
palvelinten nimien mukaiset hakemistot, joiden sisällä sijaitsevat
lokitiedostot, jotka on nimetään yhdistämällä palvelun nimi
päivämääräleimaan. Tiedostot on pakattu
\texttt{gzip}-pakkausohjelmalla. Taulukossa \ref{tiedostot}
havainnollistetaan tiedostonnimien muodostumista.

\begin{table}[h]
\centering
\begin{tabular}{llll}
Palvelin & Palvelu & Päivämäärä & Tiedostonnimi \\
\hline
edgy & buzz & 14.6.2009 & \texttt{edgy/buzz.http.2009-06-14.gz}\\ 
dapper & potato & 2.7.2009 & \texttt{dapper/potato.http.2009-07-02.gz}\\
feisty & rex & 30.7.2009 & \texttt{feisty/rex.http.2009-07-30.gz}\\
\end{tabular}
\caption{Tiedostojen nimeäminen.}
\label{tiedostot}
\end{table}

Tässä mainittujen palvelinten lisäksi käytössä on ulkoinen
välimuistipalvelu. Mikäli pyydettyä resurssia ei löydy
välimuistipalvelusta, se tekee kyselyn yhteen Web-hotellin
palvelimista ja välittää vastauksen edelleen
asiakkaalle. Välimuistipalvelun käyttö ei kuitenkaan muilta osin
vaikuta palvelun rakenteeseen. Rakenne käy ilmi kuvasta
\ref{palvelinrakenne}.

\begin{figure}[htp]
\centering
\includegraphics[width=12cm]{pics/palvelinrakenne.pdf}
\caption{Web-palvelun rakenne.}
\label{palvelinrakenne}
\end{figure}

\section{Esikäsittely}

Esikäsittely jakaantuu karkeasti ?? osaan. Aluksi 

Luvussa \ref{sec:lahtokohta} esiteltiin lokitiedostoissa
käytetty \textit{Combined Log Format} -muoto. Se ei sellaisenaan
sovellu 

\section{Analysoinnin vaiheet}

Analysointi koostuu kolmesta vaiheesta.

Toisessa vaiheessa tekstimuotoiset lokitiedostot luetaan ja
käsitellään koneellisesti helpommin analysoitavaan
muotoon. Tätä työtä varten kehitetyssä tiedonkäsittelijässä
lokitiedoston eri kentät palastellaan ja tieto tallennetaan
relaatiotietokantaan. Lopuksi eri kenttien numeeriset ja
luokka-asteikolliset arvot klusteroidaan.

Kolmannessa vaiheessa tapahtuu varsinainen analysointi. Käytetty
anomalia-analyysi edellyttää, että aineiston muuttujat ovat
luokka-asteikollisia ja tästä johtuen tieto on klusteroitu edeltävässä vaiheessa.

\subsection{Tiedon keruu}

TODO.

\subsection{Esikäsittely}

Sopivaa yksivaiheista parseria käyttämällä olisi mahdollista käsitellä
lähtödata suoraan analyysissä käytettävään muotoon. Käytännössä kuitenkin datan
esikäsittely kannattaa hoitaa useammassa vaiheessa, jotta datassa
olevat puuttuvat tai poikkeavat arvot tulee huomioitua
asianmukaisesti. Monivaiheinen esikäsittely helpottaa myös saman
lähtödatan käyttämisen useaan eri analyysiin.

Tiedon käsittelyn helpottamiseksi tässä työssä käytetään esikäsittelyn
välivaiheiden ja lopputuloksen tallentamiseen
relaatiotietokantaa. Relaatiotietokanta mahdollistaa useiden
esikäsittelyn vaiheiden suorittamisen vähäisellä ohjelmoinnilla ja
helposti ymmärrettävästi.

Tässä työssä käsiteltävää aineistoa varten on kehitetty ``PhasefulSplitter
'' -sovellus esikäsittelyä varten.

TODO.

\subsection{Kategorisointi}

TODO.
