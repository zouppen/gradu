% -*- mode: LaTeX; coding: utf-8; -*-

\chapter{Tiedon keruu ja käsittely}

Tiedon käsittely voidaan jakaa esikäsittelyyn, menetelmään ja
jälkikäsittelyyn. Esikäsittelyn tavoitteena on muuntaa palvelinlokit
muotoon, jota menetelmä pystyy käsittelemään. Menetelmävaiheessa
aineisto ajetaan diffuusiokuvausalgoritmin läpi. Jälkikäsittelyssä
luetaan diffuusiokuvauksen tuottamaa dataa ja selvitetään
mielenkiintoisten havaintojen taustalla olevat HTTP-kyselyt.

Tässä luvussa tutustutaan aluksi tutkittavien lokitiedostojen
alkuperään ja tiedostomuotoon sekä aineiston arkistointitapaan. Tämän
jälkeen käydään läpi, kuinka tietoa on esikäsitelty analyysiä silmällä
pitäen. Käytetyt menetelmät soveltuvat pienin muutoksin myös muiden
Web-palveluntarjoajien palvelinlokien esikäsittelyyn, mikäli
arkistointikäytänteet eivät suuresti poikkea tässä esitellystä.

\section{Aineiston rakenne}
\label{sec:lahtokohta}

Analysoitavaksi saamamme loki on peräisin yritykseltä, joka toimii
Web-\-palveluntarjoajana suuryrityksille. Lokitiedostot ovat peräisin
kolmelta tuotannosta jo poistetuilta palvelimilta, ja ne ovat olleet
vastuussa muutaman suuren palvelukokonaisuuden pyörittämisestä.

Analysoitava data on Apache-palvelimien tuottamaa lokia, joka sisältää
Web-palveluille kohdistuvia HTTP-pyyntöjä. Lokia on yhteensä 24
gigatavua, ja se sisältää yli 1,7 miljardia sivupyyntöä.
Lokia on kerätty noin 10 kuukauden
ajanjaksolta. Se on tallennettu \textit{Combined Log Format} -muotoon,
joka on yleinen Apache-palvelimen käyttämä lokitiedoston
muoto~\cite{combined}. Alla on esimerkki onnistuneen HTTP-kyselyn seurauksena muodostuneesta lokirivistä.

% Tarkat luvut:
% - Dataa 24133108 kiB
% - Sivupyyntöjä (ml. error-logit) on 1666171347 kpl.

\begin{framed}
\begin{verbatim*}
130.234.49.2 - - [10/May/2009:15:53:01 +0300]
"GET /scripts/access.pl?user=matti&passwd=admin HTTP/1.1"
200 2680 "http://www.jyu.fi/a.html"
"Mozilla/5.0 (SymbianOS/9.2;...)"
\end{verbatim*}
\end{framed}

Web-palvelimien tuottama loki sisältää paljon tietoa muun muassa
palveluiden käyttöasteista, ja niihin kohdistuvista kuormista. Lokeja
analysoimalla voidaan myös tunnistaa mahdollisia hyökkäysyrityksiä,
sekä hyökkäyksen jo tapahduttua tutkia siihen johtaneita
vaiheita. Pienillä sivustoilla ihmisen on mahdollista läpikäydä
lokitiedostot hyökkäyksien varalta, mutta puhuttaessa palveluista,
joilla on miljoonia käyttäjiä kuukaudessa, ei käsin läpikäyminen ole
enää käytännössä mahdollista. Tästä syystä tarvitaan lokien
analysoimisen automatisointia. Analysoinnille on kovat
laatuvaatimukset, koska järjestelmän tulisi pystyä tunnistamaan
miljoonien kyselyiden joukosta ne, jotka ovat syntyneet hyökkäyksen
johdosta.

Yksi mahdollisuus on käyttää sääntöpohjaisia suodattimia, mutta
aikaisemmin esitetyistä syistä johtuen ei tämä tarjoa aina riittävää
tunnistuskykyä. Siksi tässä tutkimuksessa on päädytty käyttämään
anomalioiden tunnistamismenetelmää. Järjestelmälle opetetaan
normaali käyttäytyminen, jonka jälkeen analysoitavaa lokia verrataan
opetettuun malliin, jolloin poikkeava liikenne voidaan tunnistaa.

Tietoturvan kannalta kiinnostavin osa lokista on HTTP-kyselyn
osoiteosa, jossa viitataan johonkin resurssiin ja välitetään
tarvittaessa parametreja. HTTP-kysely sisältää
niin staattiset sivunlatauspyynnöt kuin myös palvelimelle
välitettävät parametriarvot. Tällaisia voivat olla esimerkiksi
kirjautumisessa käytetyt tiedot ja tietokannalle välitetyt
kyselyt.

Kysely koostuu metodista, resurssista ja parametriosasta.  Metodin
jälkeen välilyönnillä erotettuna seuraa osoiteosa. Se jakautuu
resurssiin ja parametreihin, jossa erottimena toimii kysymysmerkki.
Parametriosa koostuu parametrilistasta, jossa parametrit ovat erotettu
toisistaan \texttt{\&}-merkillä. Yksittäinen parametri on
avain-arvopari, jossa avain on yhtäsuurusmerkin vasemmalla puolella ja
arvo oikealla puolella (kuva \ref{CLF2}). Käytettävien parametrien
lukumäärä vaihtelee palvelusta riippuen. Mikäli parametreja ei ole
lainkaan, ei parametriosaa eikä sitä edeltävää kysymysmerkkiä esiinny
kyselyssä. Näin on esimerkiksi silloin, kun HTTP-kysely kohdistuu
staattiseen Web-sivuun.

\vskip 0.5cm
\begin{figure}[ht]
\[
\overbrace{\texttt{GET}}^\text{metodi}
\overbrace{\texttt{/scripts/access.pl}}^\text{resurssi}
\texttt{?}
\overbrace{\underbrace{\texttt{user}}_\text{avain 1}
\texttt{=}
\underbrace{\texttt{matti}}_\text{arvo 1}
\texttt{\&}
\underbrace{\texttt{passwd}}_\text{avain 2}
\texttt{=}
\underbrace{\texttt{admin}}_\text{arvo 2}}
^{\text{parametrit}}
\]
\caption{HTTP GET -kyselyn rakenne.}
\label{CLF2}
\end{figure}


\section{Arkistointikäytänteet}

Web-hotelli, josta data on peräisin, on toteutettu siten, että yksittäiset palvelut on
sijoitettu useammalle palvelimelle. Ratkaisun taustalla on
kuormituksen tasaaminen. Erillinen järjestelmä huolehtii siitä, että
Internetistä tulevat kyselyt ohjataan tasaisesti eri
palvelimille. Tästä johtuen samaan palveluun kohdistuvat kyselyt
jakautuvat useamman palvelimen lokitiedostoihin.

Taulukossa \ref{nimet} on esimerkki palveluiden ja palvelinten
nimeämisestä. Esimerkeissä käytetyt palvelinten ja palveluiden nimet
ovat kuvitteellisia, mutta rakenne vastaa tutkittua ympäristöä.

% Ei kannata ottaa esimerkkiä tästä taulukosta, tämä on vähän mutkikas.
\begin{table}[h]
\centering
\begin{tabular}{lll}
Palvelin && Palvelu \\
\cline{1-1}\cline{3-3}
dapper && buzz \\
edgy && rex \\
feisty && potato \\
&& hamm \\
\end{tabular}
\caption{Palvelinten ja palveluiden nimeäminen.}
\label{nimet}
\end{table}

Lokitiedostot on sijoitettu hakemistorakenteeseen, jossa juuressa ovat
palvelinten nimien mukaiset hakemistot, joiden sisällä sijaitsevat
lokitiedostot, jotka on nimetään yhdistämällä palvelun nimi
päivämääräleimaan. Tiedostonnimessä käytetty päivämäärän muoto
noudattaa ISO 8601 -standardia~\cite{iso8601}. Tiedostot on pakattu
\texttt{gzip}-pakkausohjelmalla. Taulukossa \ref{tiedostot}
havainnollistetaan tiedostonnimien muodostumista.

\begin{table}[h]
\centering
\begin{tabular}{llll}
Palvelin & Palvelu & Päivämäärä & Tiedostonnimi \\
\hline
edgy & buzz & 14.6.2009 & \texttt{edgy/buzz.http.2009-06-14.gz}\\ 
dapper & potato & 2.7.2009 & \texttt{dapper/potato.http.2009-07-02.gz}\\
feisty & rex & 30.7.2009 & \texttt{feisty/rex.http.2009-07-30.gz}\\
\end{tabular}
\caption{Tiedostojen nimeäminen.}
\label{tiedostot}
\end{table}

Tässä mainittujen palvelinten lisäksi käytössä on ulkoinen
välimuistipalvelu, jonka kautta välitetään harvoin muuttuvia
resursseja, kuten kuvia. Valtaosa dataliikenteestä
välitetään palvelun kautta. Välimuistipalvelu toimii siten, että
mikäli pyydettyä resurssia ei löydy sen omasta muistista, se pyytää
sitä yhdeltä Web-hotellin palvelimista ja välittää vastauksen edelleen
asiakkaalle. Välimuistipalvelun käyttö ei kuitenkaan muilta osin
vaikuta palvelun rakenteeseen. Rakenne käy ilmi kuvasta
\ref{palvelinrakenne}.

\begin{figure}[htp]
\centering
\includegraphics[width=12cm]{pics/palvelinrakenne.pdf}
\caption{Web-palvelun rakenne.}
\label{palvelinrakenne}
\end{figure}

\section{Esikäsittely}

Luvussa \ref{sec:lahtokohta} esiteltiin lokitiedostoissa käytetty
\textit{Combined Log Format} -muoto. Tiedosto on tekstimuotoinen,
joten se ei sellaisenaan sovellu analyysivaiheeseen, jossa käsitellään
klustereita. Osa palvelinlokin sisällöstä on myös analyysin kannalta
tarpeetonta ja nämä osat tulee suodattaa pois. Lisäksi yhteen
Web-palveluun liittyvät kyselyt ovat jakautuneet useaan eri
tiedostoon eri palvelinten ja vuorokausien mukaisesti.

Esikäsittelijä on toteutettu osana tätä tutkimusta. Esikäsittelijä on
nimeltään \textit{PhasefulSplitter} ja se on toteutettu
Haskell-ohjelmointikielellä~\cite{haskell98}. Haskell tarjoaa
tehokkaat työkalut ohjelmakoodin rinnakkaistamiseen ja datan
sarjallistamiseen. \textit{PhasefulSplitter} on vapaa ohjelma ja sitä saa
levittää edelleen ja muuttaa Free Software Foundationin julkaiseman
GNU General Public Licensen (GPL-lisenssi) version 3~\cite{gplv3} tai (valinnan
mukaan) myöhemmän version ehtojen mukaisesti. Sovellus on
ladattavissa Internetistä osoitteesta \\
\url{http://iki.fi/zouppen/repo/phasefulsplitter.git}.

Sopivaa yksivaiheista parseria käyttämällä olisi mahdollista käsitellä
lähtödata suoraan analyysissä käytettävään muotoon. Käytännössä
kuitenkin datan esikäsittely kannattaa hoitaa useammassa vaiheessa,
jotta datassa olevat puuttuvat tai poikkeavat arvot voidaan huomioida
ja esikäsittelijää voidaan korjata suorittamatta koko ajoa uudelleen
alusta lähtien. Monivaiheinen esikäsittely helpottaa myös datan
käsittelyä jälkikäteen erilaisin menetelmin. Lisäksi sarjallistetut
tietorakenteet voidaan tarvittaessa anonymisoida, jolloin dataa
voidaan luovuttaa myös ulkopuoliseen käyttöön.

Tiedon käsittelyn helpottamiseksi tässä työssä käytetään esikäsittelyn
välivaiheet ja lopputulokset tallennetaan väliaikaistiedostoihin.
Relaatiotietokantaa ei käytetä, koska tietokantakyselyiden
rinnakkaistaminen osoittautui hyvin vaikeaksi verrattuna suoraan
tiedostoja käsittelevään toteutukseen.

Esikäsittely jakaantuu seuraavaat neljään vaiheeseen:

\begin{enumerate}
\item Tiedostolistan muodostaminen ja tiedostojen ryhmittely palveluittain.
\item Tiedostojen sisällön lukeminen ja muuntaminen tietorakenteeksi.
\item N-grammien muodostaminen HTTP-kyselyn parametreista.
\item Aineiston muuntaminen matriisimuotoon analyysiä varten.
\end{enumerate}

Seuraavaksi käydään läpi esimerkkien tuella se, kuinka nämä vaiheet
voidaan suorittaa.

\subsection{Tiedostolistan muodostaminen}

Tekstipohjainen tiedostolista luetaan
\textit{PhasefulSplitter}-ohjelman ymmärtämään muotoon, jolloin
tiedostonnimet ryhmitellään palveluiden nimien perusteella. 

Luokittelun yhteydessä palvelinten nimet korvataan numeerisilla
viitteillä. Tätä varten asetetaan tiedestoon \texttt{server.map}
palvelinten nimet ja niitä vastaavat numeeriset viitteet. Viitteitä
voidaan hyödyntää myöhemmin, jos halutaan muuntaa analyysivaiheessa
kiinnostava havainto takaisin Apache-lokin riviksi. Tässä luvun
esimerkissä käytettävän tiedoston sisältö on esitelty listauksessa
\ref{servermap}

\begin{lstlisting}[language=MyHaskell,float=h,caption=Tiedoston server.map sisältö.,label=servermap,aboveskip=1cm]
[
      ("dapper",1)
    , ("edgy",2)
    , ("feisty",3)
]
\end{lstlisting}

Tiedostolista voidaan muodostaa
Linux-järjestelmässä seuraavalla tavalla:

\begin{lstlisting}[language=bashshell]
mkdir lists
find [[polku]] -iname '*.gz' | classifier lists/
\end{lstlisting} 
\label{filelist}

Ajon yhteydessä muodostuu hakemiston \texttt{lists} alle palveluiden
mukaan nimetyt tiedostot. Tiedostomuoto joiden sisällä on palveluun kuuluvat
tiedostonnimet sekä tiedon siitä, minkä palvelimen lokitiedostosta on kyse. Tiedostot ovat tekstimuotoon sarjallistettuja.

\subsection{Muuntaminen tietorakenteeksi}

Toisessa vaiheessa tekstimuotoiset lokitiedostot luetaan ja
käsitellään koneellisesti helpommin analysoitavaan muotoon. Tätä työtä
varten kehitetyssä tiedonkäsittelijässä lokitiedoston rivin eri kentät
palastellaan ja kyselyt sarjallistetaan tiedostoihin. Tietorakenne on
esitelty listauksessa \ref{entry}.

\lstset{language=MyHaskell}

\begin{lstlisting}[float=h,caption=Yhden lokirivin säilövä tietorakenne.,label=entry,aboveskip=1cm]
data Entry = Entry {
      info      :: LineInfo
    , ip        :: ByteString
    , date      :: UTCTime
    , method    :: ByteString
    , url       :: URL
    , protocol  :: ByteString
    , response  :: Integer
    , bytes     :: Integer
    , referer   :: ByteString
    , browser   :: ByteString
} deriving (Show,Eq)
\end{lstlisting}

Koska jatkokäsittely voidaan hoitaa säikeistettynä useammalle
prosessorille tai ytimelle, tässä vaiheessa sovellukselle tulee
ilmoittaa säikeiden määrä. Tiedon perusteella sovellus jakaa yhteen
palveluun liittyvän datan haluttuun määrään erillisiä tiedostoja. Jako
mahdollistaa tehokkaan jälkikäsittelyn, koska tiedostojen sisältöä on
mahdollista käsitellä myöhemmin samanaikaisesti.

Linuxin \texttt{xargs}-komennolla voidaan myös tämän vaihe suorittaa
rinnakkaistettuna, jolloin eri palveluihin kuuluva data voidaan
muuntaa samanaikaisesti. Mikäli eri palveluihin kuuluvien lokien datamäärä
vaihtelee, ei rinnakkaistamisesta kuitenkaan saavuteta täyttä hyötyä.

Alla olevassa esimerkissä esikäsitellään \texttt{lists}-hakemistosta
löytyvät tiedostolistat ja kirjoitetaan ne hakemiston \texttt{data}
alle. Korvaa listauksessa esiintyvä N tietokoneen prosessorien tai
ytimien määrällä. 

\begin{lstlisting}[language=bashshell]
ls lists/*| xargs -n 1 -I{} -P [[N]] apache2data [[N]] {} data/
\end{lstlisting}

Suoritusaika riippuu luonnollisesti koneen suorituskyvystä ja
lokitiedostojen määrästä. Tämän tutkimuksen yhteydessä suoritetussa 24
gigatavun ajossa 2,5 gigahertsin Intel Xeon -prosessorilla varustetussa
tietokoneessa tämän vaiheen suoritus kesti useita
prosessorivuorokausia.

\subsection{Parametrien N-grammianalyysi}

Palvelinlokissa olevista kyselyistä muodostetaan tietorakenne, jossa
yksi osa on kyselyn URL. Tässä vaiheessa tutkitaan URL-osoitetta
tarkemmin. Mikäli URL:n osana on parametreja, muodostetaan jokaisesta
parametrin arvosta 2-grammilistaus. Näin saadut 2-grammikartat
muodostetaan ja lopuksi ne tallennetaan matriisina tekstimuotoon
jatkokäsittelyä varten. Tiedostossa \texttt{ParameterAnalyzer.hs} on
määritelty vakiona, että lasketaan nimenomaisesti 2-grammit. Tätä
vakiota voi kuitenkin tarvittaessa muuttaa.

Ensimmäisessä ajossa selvitetään, mitkä mahdollisista 2-grammeista
ylipäätään esiintyvät aineistossa. Mahdollisia N-grammeja on yhteensä
$2^{8n}$ kappaletta, koska käsiteltävät merkkijonot koostuvat
Word8-tyypeistä (8-bittinen tavu). Säästääkseme muistia
analyysivaiheessa, selvitetään aluksi, millaisia 2-grammeja
aineistossa esiintyy ja jätetään taulukoimatta sellaiset 2-grammit,
jotka eivät esiinny lainkaan.

Jokaiselle resurssille muodostuu oma N-grammilistansa. Datan määrä
luonnollisesti riippuu käytettävästä aineistosta. Käyttämällämme
datalla taulukon kooksi muodostuu muutamia megatavuja (FIXME täsmällisesti).
Lopputulos on kuitenkin vain murto-osa alkuperäisen datamassan
suuruudesta.

N-grammianalyysin ensimmäinen vaihe suoritetaan menemällä halutun
palvelun mukaiseen hakemistoon ja suorittamalla seuraavan komennon:

\begin{lstlisting}[language=bashshell]
parameter_analyzer *.pf.gz +RTS -N
\end{lstlisting} 

Hakemistoon muodostuu ajon seurauksena tiedostot \texttt{ngrams.out}
ja \texttt{grams\_raw.txt}. Näistä ensimmäinen on binaarimuodossa ja
sisältää toisessa vaiheessa tarvittavan datan
binaarimuodossa. Toisessa tiedostossa on tekstimuodossa (Haskellin
show-muodossa) eri resurssien ja 2-grammien
esiintymistiheydet. Tekstimuotoista tiedostoa voidaan käyttää apuna
arvioitaessa, mihin resursseihin ja parametreihin kannattaa kiinnittää
jatkossa huomiota.

\subsection{Matriisien muodostaminen tietorakenteista}

Tämän vaiheen yhteydessä aineistossa esiintyvät eri tyyppiset arvot
numeroidaan. 

TODO

HTTP Method -kentässä esiintyvät arvot numeroidaan
seuraavasti:

% Merkkijonoja sisältävät arvot toimivat kukin omana ryhmänään.

\begin{table}[h]
\centering
\begin{tabular}{llll}
HTTP method & Klusteri \\
\hline
HEAD & 1 \\
GET & 2 \\
POST & 3 \\
PUT & 4 \\
DELETE & 5 \\
TRACE & 6 \\
OPTIONS & 7 \\
CONNECT & 8 \\
PATCH & 9 \\

\end{tabular}
\caption{HTTP Method -kentän numerointi.}
\label{tiedostot}
\end{table}


\begin{table}[h]
\centering
\begin{tabular}{llll}
HTTP:n versio & Klusteri \\
\hline
HTTP/1.0 & 1 \\
HTTP/1.1 & 2 \\
\end{tabular}
\caption{ HTTP:n versiokentän numerointi..}
\label{tiedostot}
\end{table}


Käyttämässämme datassa olevat kyselyiden parametrit sisältävät hyvin
samantyyppisiä arvoja, joten niistä muodostuu kohtuullisen
pieniulotteisia 2-\-grammitaulukoita. Tässä tutkimuksessa käytetyllä
aineistolla suurin esiintynyt 2-grammien lukumäärä oli
189. Käytännössä havaittiin, että käyttämällämme laitteistolla alle
200 saraketta sisältävän matriisin laskenta oli riittävän
nopeaa. Tämän vuoksi dimensioita ei tarvitse vähentää, joten matriiseihin ei sovelleta
satunnaisprojektiota. Sen sijaan muodostetaan matriisi, jossa
luetellaan kussakin HTTP-kyselyssä esiintyvien N-grammien
esiintymistiheydet. Näin muodostetun matriisin tiedot liitetään
aiemmin kerättyjen parametrien perään.

Analyysissä käytettävät matriisit muodostetaan
\texttt{parameter2vector}-sovelluksella. Listauksessa \ref{p2v}
esiintyvä parametri \texttt{ngram} korvataan edellisessä vaiheessa
muodostuneella N-\-grammitiedoston nimellä, \texttt{lahde} korvataan
tietorakennetiedoston nimellä ja parametrissa \texttt{kohde}
määritellään muodostettavien matriisitiedostojen nimen alkuosa.

\begin{lstlisting}[float=h,language=bashshell,label=p2v,caption=Matriisien
  muodostaminen.]
parameter2vector ngram lahde kohde
\end{lstlisting} 



% Tässä vaiheessa kuvassa \ref{ngramdata} esiintyvä tietorakenne
% muunnetaan matriisimuotoon.

%data ParamInfo = ParamInfo {
%      paramCount :: Integer                    -- ^Frequency of this parameter.
%    , ngramMap   :: M.Map (Ngram Char) Integer -- ^N-grams.
%    } deriving (Show,Read,Eq)

%data ResourceStat = ResourceStat {
%      resourceCount :: Integer                 -- ^Frequency of this resource.
%    , params        :: M.Map String ParamInfo  -- ^Key and its n-gram.
%} deriving (Show,Read,Eq)


TODO

\section{Matlab toteutus}
\label{sec:matlab}

Diffuusikuvausten laskemiseen voidaan käyttää korkeintaan noin 5000 yksittäistä pistettä 2000 pisteen ollessa laskennallisesti vielä tehokasta. Rajoitus johtuu siitä, että
algoritmin aikavaativuus kasvaa eksponentiaalisesti verrattaessa opetusmateriaalin kokoon. 

\section{Pisteen takaisin muuntaminen palvelinlokin riviksi}

LineInfo-tietorakennetta kuljetetaan esikäsittelyvaiheesta
lähtien datan mukana. Tietorakenne tallennetaan matriisin kolmeen
ensimmäiseen sarakkeeseen, eli tekstimuotoisessa esityksessä se
sijaitsee rivin kolmessa ensimmäisessä pilkulla erotetussa kentässä.


kaikki anomaliat kaikissa resursseissa:

%a <- readZipolaFile "/home/joell/zipolalta/service_a_anomalies.csv"
%saveLogLines tiedostolistaus kohde a

%anomaliat resursseittain ryhmiteltynä:

%backtrackCSVnumeric
%tiedostolistaus
%vektorihakemisto
%kohde
%[1,18,337,721,723,882]

TODO
